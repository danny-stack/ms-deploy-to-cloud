{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/how-to-use-azureml/deployment/deploy-to-cloud/model-register-and-deploy.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Register model and deploy as webservice in ACI\n",
        "\n",
        "Following this notebook, you will:\n",
        "\n",
        " - Learn how to register a model in your Azure Machine Learning Workspace.\n",
        " - Deploy your model as a web service in an Azure Container Instance."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "\n",
        "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the [configuration notebook](../../../configuration.ipynb) to install the Azure Machine Learning Python SDK and create a workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "\n",
        "\n",
        "# Check core SDK version number.\n",
        "print('SDK version:', azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.57.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1738250219138
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize workspace\n",
        "\n",
        "Create a [Workspace](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace%28class%29?view=azure-ml-py) object from your persisted configuration."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "micro-project-danny\nucablx0-rg\nuksouth\nafc44d03-4b64-4999-a2f3-cdb190d6c505\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "tags": [
          "create workspace"
        ],
        "gather": {
          "logged": 1738250235156
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create trained model\n",
        "\n",
        "For this example, we will train a small model on scikit-learn's [diabetes dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html). "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import dill\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "\n",
        "dataset_x, dataset_y = load_diabetes(return_X_y=True)\n",
        "\n",
        "model = Ridge().fit(dataset_x, dataset_y)\n",
        "\n",
        "dill.dump(model, open('sklearn_regression_model.pkl', 'wb'))"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1738250256543
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register input and output datasets\n",
        "\n",
        "Here, you will register the data used to create the model in your workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from azureml.core import Dataset\n",
        "\n",
        "\n",
        "np.savetxt('features.csv', dataset_x, delimiter=',')\n",
        "np.savetxt('labels.csv', dataset_y, delimiter=',')\n",
        "\n",
        "datastore = ws.get_default_datastore()\n",
        "datastore.upload_files(files=['./features.csv', './labels.csv'],\n",
        "                       target_path='sklearn_regression/',\n",
        "                       overwrite=True)\n",
        "\n",
        "input_dataset = Dataset.Tabular.from_delimited_files(path=[(datastore, 'sklearn_regression/features.csv')])\n",
        "output_dataset = Dataset.Tabular.from_delimited_files(path=[(datastore, 'sklearn_regression/labels.csv')])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 2 files\nUploading ./features.csv\nUploaded ./features.csv, 1 files out of an estimated total of 2\nUploading ./labels.csv\nUploaded ./labels.csv, 2 files out of an estimated total of 2\nUploaded 2 files\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1738250277447
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register model\n",
        "\n",
        "Register a file or folder as a model by calling [Model.register()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py#register-workspace--model-path--model-name--tags-none--properties-none--description-none--datasets-none--model-framework-none--model-framework-version-none--child-paths-none-).\n",
        "\n",
        "In addition to the content of the model file itself, your registered model will also store model metadata -- model description, tags, and framework information -- that will be useful when managing and deploying models in your workspace. Using tags, for instance, you can categorize your models and apply filters when listing models in your workspace. Also, marking this model with the scikit-learn framework will simplify deploying it as a web service, as we'll see later."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "from azureml.core import Model\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\n",
        "\n",
        "\n",
        "model = Model.register(workspace=ws,\n",
        "                       model_name='my-sklearn-model',                # Name of the registered model in your workspace.\n",
        "                       model_path='./sklearn_regression_model.pkl',  # Local file to upload and register as a model.\n",
        "                       model_framework=Model.Framework.SCIKITLEARN,  # Framework used to create the model.\n",
        "                       model_framework_version=sklearn.__version__,  # Version of scikit-learn used to create the model.\n",
        "                       sample_input_dataset=input_dataset,\n",
        "                       sample_output_dataset=output_dataset,\n",
        "                       resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=0.5),\n",
        "                       description='Ridge regression model to predict diabetes progression.',\n",
        "                       tags={'area': 'diabetes', 'type': 'regression'})\n",
        "\n",
        "print('Name:', model.name)\n",
        "print('Version:', model.version)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Registering model my-sklearn-model\nName: my-sklearn-model\nVersion: 1\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "tags": [
          "register model from file",
          "sample-model-register"
        ],
        "gather": {
          "logged": 1738250353356
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy model\n",
        "\n",
        "Deploy your model as a web service using [Model.deploy()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py#deploy-workspace--name--models--inference-config--deployment-config-none--deployment-target-none-). Web services take one or more models, load them in an environment, and run them on one of several supported deployment targets. For more information on all your options when deploying models, see the [next steps](#Next-steps) section at the end of this notebook.\n",
        "\n",
        "For this example, we will deploy your scikit-learn model to an Azure Container Instance (ACI)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use a default environment (for supported models)\n",
        "\n",
        "The Azure Machine Learning service provides a default environment for supported model frameworks, including scikit-learn, based on the metadata you provided when registering your model. This is the easiest way to deploy your model.\n",
        "\n",
        "Even when you deploy your model to ACI with a default environment you can still customize the deploy configuration (i.e. the number of cores and amount of memory made available for the deployment) using the [AciWebservice.deploy_configuration()](https://docs.microsoft.com/python/api/azureml-core/azureml.core.webservice.aci.aciwebservice#deploy-configuration-cpu-cores-none--memory-gb-none--tags-none--properties-none--description-none--location-none--auth-enabled-none--ssl-enabled-none--enable-app-insights-none--ssl-cert-pem-file-none--ssl-key-pem-file-none--ssl-cname-none--dns-name-label-none--). Look at the \"Use a custom environment\" section of this notebook for more information on deploy configuration.\n",
        "\n",
        "**Note**: This step can take several minutes.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "service_name = 'my-sklearn-service'\n",
        "\n",
        "service = Model.deploy(ws, service_name, [model], overwrite=True)\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "After your model is deployed, perform a call to the web service using [service.run()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice%28class%29?view=azure-ml-py#run-input-)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "\n",
        "input_payload = json.dumps({\n",
        "    'data': dataset_x[0:2].tolist(),\n",
        "    'method': 'predict'  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
        "})\n",
        "\n",
        "output = service.run(input_payload)\n",
        "\n",
        "print(output)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you are finished testing your service, clean up the deployment with [service.delete()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice%28class%29?view=azure-ml-py#delete--)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "service.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use a custom environment\n",
        "\n",
        "If you want more control over how your model is run, if it uses another framework, or if it has special runtime requirements, you can instead specify your own environment and scoring method. Custom environments can be used for any model you want to deploy.\n",
        "\n",
        "Specify the model's runtime environment by creating an [Environment](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.environment%28class%29?view=azure-ml-py) object and providing the [CondaDependencies](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.conda_dependencies.condadependencies?view=azure-ml-py) needed by your model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "\n",
        "environment = Environment('my-sklearn-environment')\n",
        "environment.python.conda_dependencies = CondaDependencies.create(conda_packages=[\n",
        "    'pip==20.2.4'],\n",
        "    pip_packages=[\n",
        "    'azureml-defaults',\n",
        "    'inference-schema[numpy-support]',\n",
        "    'joblib',\n",
        "    'dill==0.3.6',\n",
        "    'numpy==1.23',\n",
        "    'scikit-learn=={}'.format(sklearn.__version__)\n",
        "])"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1738250658158
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using a custom environment, you must also provide Python code for initializing and running your model. An example script is included with this notebook."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open('score.py') as f:\n",
        "    print(f.read())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "import joblib\nimport numpy as np\nimport os\n\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n\n\n# The init() method is called once, when the web service starts up.\n#\n# Typically you would deserialize the model file, as shown here using joblib,\n# and store it in a global variable so your run() method can access it later.\ndef init():\n    global model\n\n    # The AZUREML_MODEL_DIR environment variable indicates\n    # a directory containing the model file you registered.\n    model_filename = 'sklearn_regression_model.pkl'\n    model_path = os.path.join(os.environ['AZUREML_MODEL_DIR'], model_filename)\n\n    model = joblib.load(model_path)\n\n\n# The run() method is called each time a request is made to the scoring API.\n#\n# Shown here are the optional input_schema and output_schema decorators\n# from the inference-schema pip package. Using these decorators on your\n# run() method parses and validates the incoming payload against\n# the example input you provide here. This will also generate a Swagger\n# API document for your web service.\n@input_schema('data', NumpyParameterType(np.array([[0.1, 1.2, 2.3, 3.4, 4.5, 5.6, 6.7, 7.8, 8.9, 9.0]])))\n@output_schema(NumpyParameterType(np.array([4429.929236457418])))\ndef run(data):\n    # Use the model object loaded by init().\n    result = model.predict(data)\n\n    # You can return any JSON-serializable object.\n    return result.tolist()\n\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1738250668876
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deploy your model in the custom environment by providing an [InferenceConfig](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.inferenceconfig?view=azure-ml-py) object to [Model.deploy()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py#deploy-workspace--name--models--inference-config--deployment-config-none--deployment-target-none-). In this case we are also using the [AciWebservice.deploy_configuration()](https://docs.microsoft.com/python/api/azureml-core/azureml.core.webservice.aci.aciwebservice#deploy-configuration-cpu-cores-none--memory-gb-none--tags-none--properties-none--description-none--location-none--auth-enabled-none--ssl-enabled-none--enable-app-insights-none--ssl-cert-pem-file-none--ssl-key-pem-file-none--ssl-cname-none--dns-name-label-none--) method to generate a custom deploy configuration.\n",
        "\n",
        "**Note**: This step can take several minutes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "\n",
        "service_name = 'my-custom-env-service'\n",
        "\n",
        "inference_config = InferenceConfig(entry_script='score.py', environment=environment)\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "service = Model.deploy(workspace=ws,\n",
        "                       name=service_name,\n",
        "                       models=[model],\n",
        "                       inference_config=inference_config,\n",
        "                       deployment_config=aci_config,\n",
        "                       overwrite=True)\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_3104/1538916731.py:10: FutureWarning: azureml.core.model:\nTo leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \nplease refer to respective documentations \nhttps://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\nhttps://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \nFor more information on migration, see https://aka.ms/acimoemigration \nTo disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n  service = Model.deploy(workspace=ws,\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2025-01-30 15:29:11+00:00 Creating Container Registry if not exists..\n2025-01-30 15:39:12+00:00 Registering the environment.\n2025-01-30 15:39:13+00:00 Building image..\n2025-01-30 15:47:26+00:00 Generating deployment configuration.\n2025-01-30 15:47:27+00:00 Submitting deployment to compute..\n2025-01-30 15:47:34+00:00 Checking the status of deployment my-custom-env-service..\n2025-01-30 15:49:00+00:00 Checking the status of inference endpoint my-custom-env-service.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "tags": [
          "azuremlexception-remarks-sample",
          "sample-aciwebservice-deploy-config"
        ],
        "gather": {
          "logged": 1738252144870
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After your model is deployed, make a call to the web service using [service.run()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice%28class%29?view=azure-ml-py#run-input-)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "input_payload = json.dumps({\n",
        "    'data': dataset_x[0:2].tolist()\n",
        "})\n",
        "\n",
        "output = service.run(input_payload)\n",
        "\n",
        "print(output)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[182.67335420683418, 90.99860655841785]\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1738252155391
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you are finished testing your service, clean up the deployment with [service.delete()](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice%28class%29?view=azure-ml-py#delete--)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "service.delete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Running\n2025-01-30 15:55:48+00:00 Check and wait for operation (c88f5434-cb02-4235-a8ce-c4a7d7b1975d) to finish.\n2025-01-30 15:55:50+00:00 Deleting service entity.\nSucceeded\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1738252554016
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Profiling\n",
        "\n",
        "Profile your model to understand how much CPU and memory the service, created as a result of its deployment, will need. Profiling returns information such as CPU usage, memory usage, and response latency. It also provides a CPU and memory recommendation based on the resource usage. You can profile your model (or more precisely the service built based on your model) on any CPU and/or memory combination where 0.1 <= CPU <= 3.5 and 0.1GB <= memory <= 15GB. If you do not provide a CPU and/or memory requirement, we will test it on the default configuration of 3.5 CPU and 15GB memory.\n",
        "\n",
        "In order to profile your model you will need:\n",
        "- a registered model\n",
        "- an entry script\n",
        "- an inference configuration\n",
        "- a single column tabular dataset, where each row contains a string representing sample request data sent to the service.\n",
        "\n",
        "Please, note that profiling is a long running operation and can take up to 25 minutes depending on the size of the dataset.\n",
        "\n",
        "At this point we only support profiling of services that expect their request data to be a string, for example: string serialized json, text, string serialized image, etc. The content of each row of the dataset (string) will be put into the body of the HTTP request and sent to the service encapsulating the model for scoring.\n",
        "\n",
        "Below is an example of how you can construct an input dataset to profile a service which expects its incoming requests to contain serialized json. In this case we created a dataset based one hundred instances of the same request data. In real world scenarios however, we suggest that you use larger datasets with various inputs, especially if your model resource usage/behavior is input dependent.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may want to register datasets using the register() method to your workspace so they can be shared with others, reused and referred to by name in your script.\n",
        "You can try get the dataset first to see if it's already registered."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Datastore\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.data import dataset_type_definitions\n",
        "\n",
        "dataset_name='diabetes_sample_request_data'\n",
        "\n",
        "dataset_registered = False\n",
        "try:\n",
        "    sample_request_data = Dataset.get_by_name(workspace = ws, name = dataset_name)\n",
        "    dataset_registered = True\n",
        "except:\n",
        "    print(\"The dataset {} is not registered in workspace yet.\".format(dataset_name))\n",
        "\n",
        "if not dataset_registered:\n",
        "    # create a string that can be utf-8 encoded and\n",
        "    # put in the body of the request\n",
        "    serialized_input_json = json.dumps({\n",
        "        'data': [\n",
        "            [ 0.03807591,  0.05068012,  0.06169621, 0.02187235, -0.0442235,\n",
        "            -0.03482076, -0.04340085, -0.00259226, 0.01990842, -0.01764613]\n",
        "        ]\n",
        "    })\n",
        "    dataset_content = []\n",
        "    for i in range(100):\n",
        "        dataset_content.append(serialized_input_json)\n",
        "    dataset_content = '\\n'.join(dataset_content)\n",
        "    file_name = \"{}.txt\".format(dataset_name)\n",
        "    f = open(file_name, 'w')\n",
        "    f.write(dataset_content)\n",
        "    f.close()\n",
        "\n",
        "    # upload the txt file created above to the Datastore and create a dataset from it\n",
        "    data_store = Datastore.get_default(ws)\n",
        "    data_store.upload_files(['./' + file_name], target_path='sample_request_data')\n",
        "    datastore_path = [(data_store, 'sample_request_data' +'/' + file_name)]\n",
        "    sample_request_data = Dataset.Tabular.from_delimited_files(\n",
        "        datastore_path,\n",
        "        separator='\\n',\n",
        "        infer_column_types=True,\n",
        "        header=dataset_type_definitions.PromoteHeadersBehavior.NO_HEADERS)\n",
        "    sample_request_data = sample_request_data.register(workspace=ws,\n",
        "                                                    name=dataset_name,\n",
        "                                                    create_new_version=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have an input dataset we are ready to go ahead with profiling. In this case we are testing the previously introduced sklearn regression model on 1 CPU and 0.5 GB memory. The memory usage and recommendation presented in the result is measured in Gigabytes. The CPU usage and recommendation is measured in CPU cores."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "\n",
        "environment = Environment('my-sklearn-environment')\n",
        "environment.python.conda_dependencies = CondaDependencies.create(conda_packages=[\n",
        "    'pip==20.2.4'],\n",
        "    pip_packages=[\n",
        "    'azureml-defaults',\n",
        "    'inference-schema[numpy-support]',\n",
        "    'joblib',\n",
        "    'dill==0.3.6',\n",
        "    'numpy==1.23',\n",
        "    'scikit-learn=={}'.format(sklearn.__version__)\n",
        "])\n",
        "inference_config = InferenceConfig(entry_script='score.py', environment=environment)\n",
        "# if cpu and memory_in_gb parameters are not provided\n",
        "# the model will be profiled on default configuration of\n",
        "# 3.5CPU and 15GB memory\n",
        "profile = Model.profile(ws,\n",
        "            'rgrsn-%s' % datetime.now().strftime('%m%d%Y-%H%M%S'),\n",
        "            [model],\n",
        "            inference_config,\n",
        "            input_dataset=sample_request_data,\n",
        "            cpu=1.0,\n",
        "            memory_in_gb=0.5)\n",
        "\n",
        "# profiling is a long running operation and may take up to 25 min\n",
        "profile.wait_for_completion(True)\n",
        "details = profile.get_details()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model packaging\n",
        "\n",
        "If you want to build a Docker image that encapsulates your model and its dependencies, you can use the model packaging option. The output image will be pushed to your workspace's ACR.\n",
        "\n",
        "You must include an Environment object in your inference configuration to use `Model.package()`.\n",
        "\n",
        "```python\n",
        "package = Model.package(ws, [model], inference_config)\n",
        "package.wait_for_creation(show_output=True)  # Or show_output=False to hide the Docker build logs.\n",
        "package.pull()\n",
        "```\n",
        "\n",
        "Instead of a fully-built image, you can also generate a Dockerfile and download all the assets needed to build an image on top of your Environment.\n",
        "\n",
        "```python\n",
        "package = Model.package(ws, [model], inference_config, generate_dockerfile=True)\n",
        "package.wait_for_creation(show_output=True)\n",
        "package.save(\"./local_context_dir\")\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps\n",
        "\n",
        " - To run a production-ready web service, see the [notebook on deployment to Azure Kubernetes Service](../production-deploy-to-aks/production-deploy-to-aks.ipynb).\n",
        " - To run a local web service, see the [notebook on deployment to a local Docker container](../deploy-to-local/register-model-deploy-local.ipynb).\n",
        " - For more information on datasets, see the [notebook on training with datasets](../../work-with-data/datasets-tutorial/train-with-datasets/train-with-datasets.ipynb).\n",
        " - For more information on environments, see the [notebook on using environments](../../training/using-environments/using-environments.ipynb).\n",
        " - For information on all the available deployment targets, see [&ldquo;How and where to deploy models&rdquo;](https://docs.microsoft.com/azure/machine-learning/v1/how-to-deploy-and-where#choose-a-compute-target)."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "index_order": 3,
    "exclude_from_index": false,
    "task": "Deploy a model with Azure Machine Learning",
    "deployment": [
      "Azure Container Instance"
    ],
    "authors": [
      {
        "name": "vaidyas"
      }
    ],
    "star_tag": [
      "featured"
    ],
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "compute": [
      "None"
    ],
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "tags": [
      "None"
    ],
    "datasets": [
      "Diabetes"
    ],
    "categories": [
      "SDK v1",
      "how-to-use-azureml",
      "deployment"
    ],
    "category": "deployment",
    "framework": [
      "Scikit-learn"
    ],
    "friendly_name": "Register model and deploy as webservice",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}